{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Reinforcement learning algorithms solve MDP-based control problems having the agent interact with\n",
    "the environment (i.e., sampling) and learning from its experience. In order to do so, the agent will\n",
    "try to maximize the expected return, or _expected cumulative reward_ (reward hypothesis).\n",
    "\n",
    "## Type of Tasks\n",
    "\n",
    "Before we proceed, let's introduce some useful concepts. There are two types of RL tasks:\n",
    "\n",
    " * **Episodic:** The task has one or more end (or _terminal_) states. For example, our grid world\n",
    "   robot task ends either in the bomb or in the target.\n",
    " * **Continuous:** The task never ends, there are no terminal states. The agent keeps interacting\n",
    "   with the environment (e.g., stock trading agent).\n",
    "\n",
    "## Approaches\n",
    "\n",
    "Finally, there are two main approaches for solving an RL problem:\n",
    "\n",
    " * **Value-based:** The agent learns an optimal value function (e.g., $Q(s,a)$), and then derives\n",
    "   the optimal policy from it (see previous lecture). For now, we will focus on these methods.\n",
    " * **Policy-based:** The agent learns an optimal policy directly. We will learn about a popular\n",
    "   category of algorithms of this kind later on (i.e., _policy gradient_ methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For reproducibility.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgymnastics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_random\n\u001b[1;32m      3\u001b[0m init_random()\n",
      "File \u001b[0;32m~/Code/drl-zh/util/gymnastics.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordVideo\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NamedTuple\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# The device to use for PyTorch. Just defined here for convenience.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/editor.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYGAME_HIDE_SUPPORT_PROMPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Clips\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_webfile\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/video/io/VideoFileClip.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioFileClip\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFMPEG_VideoReader\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/audio/io/AudioFileClip.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioClip\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFMPEG_AudioReader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAudioFileClip\u001b[39;00m(AudioClip):\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/audio/AudioClip.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mproglog\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_audiowriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ffmpeg_audiowrite\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m requires_duration\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/audio/io/ffmpeg_audiowriter.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mproglog\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEVNULL\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_setting\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m requires_duration\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFFMPEG_AudioWriter\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/moviepy/config.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg-imageio\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_exe\n\u001b[0;32m---> 36\u001b[0m     FFMPEG_BINARY \u001b[38;5;241m=\u001b[39m \u001b[43mget_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto-detect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m try_cmd([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/imageio/plugins/ffmpeg.py:173\u001b[0m, in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exe\u001b[39m():  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for imageio_ffmpeg.get_ffmpeg_exe()\"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimageio_ffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ffmpeg_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drlzh/lib/python3.11/site-packages/imageio_ffmpeg/_utils.py:34\u001b[0m, in \u001b[0;36mget_ffmpeg_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exe\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Nothing was found\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo ffmpeg exe could be found. Install ffmpeg on your system, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set the IMAGEIO_FFMPEG_EXE environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable."
     ]
    }
   ],
   "source": [
    "# For reproducibility.\n",
    "from util.gymnastics import init_random\n",
    "init_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Updated Grid World\n",
    "\n",
    "To examine our RL algorithms, we will use a slightly more complicated version of our grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.gridworld import Grid, GridMDP, run_simulation, RANDOM_POLICY\n",
    "\n",
    "WORLD_GRID = Grid([\n",
    "    'EEEEE',\n",
    "    'EWTNG',\n",
    "    'SEEEW',\n",
    "])\n",
    "\n",
    "MDP = GridMDP(WORLD_GRID, gamma=0.9)\n",
    "\n",
    "run_simulation(MDP, RANDOM_POLICY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing\n",
    "\n",
    "How do we refine the expected value of a variable `X` given a series of samples? One technique that\n",
    "we will use extensively is iteratively applying an\n",
    "[_exponential moving average_](https://en.wikipedia.org/wiki/Exponential_smoothing) of the samples.\n",
    "\n",
    "$$\n",
    "X_{t+1} =  (1 - \\alpha) X_t + \\alpha X_{t+1}\n",
    "$$\n",
    "\n",
    "Basically, the adjusted value after sampling is a \"blend\" of the old value adjusted by the scaled\n",
    "value of the new sample. $\\alpha$ is the scaling factor (or, _learning rate_). We can rewrite the\n",
    "above as:\n",
    "\n",
    "$$\n",
    "X_{t+1} =  X_t + \\alpha (X_{t+1} - X_t)\n",
    "$$\n",
    "\n",
    "Where the difference between the new and old value is effectively an error $\\delta$ scaled by the\n",
    "learning rate $\\alpha$. You will see why this formula is very important shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated expected value: 3.13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Samples 1M values from a normal distribution with mean pi.\n",
    "samples = np.random.normal(loc=3.14159265, scale=1.618033, size=(1_000_000,))\n",
    "\n",
    "def estimate_mean(samples, alpha=0.0001) -> float:\n",
    "    \"\"\"Approximates the expected value using exponential smoothing.\"\"\"\n",
    "    value = samples[0]\n",
    "    for sample in samples[1:]:\n",
    "        value = value + alpha * (sample - value)\n",
    "    return value\n",
    "\n",
    "# This should print a value very close to 3.14 :)\n",
    "print(f'Estimated expected value: {estimate_mean(samples):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Methods\n",
    "\n",
    "Monte Carlo methods apply to episodic tasks. The intuition is that we can simulate entire episodes\n",
    "and compute the actual return with which we can then update our value function.\n",
    "\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha [G_t - Q(S_t, A_t)] \n",
    "$$\n",
    "\n",
    "Monte Carlo methods do not introduce _bias_ in the estimation (because they use the actual return at\n",
    "the end of the episode), but they might have high _variance_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gridworld import GridEnv, State, Action\n",
    "from typing import Callable, TypeAlias\n",
    "\n",
    "# For simplicity, we define a policy as a function that returns an action given a state.\n",
    "Policy:  TypeAlias = Callable[[State], Action]\n",
    "\n",
    "# An episode instead is a list of tuples (state, action, reward).\n",
    "Episode: TypeAlias = list[tuple[State, Action, float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our definition\n",
    "assert Policy == Callable[[State], Action]\n",
    "assert Episode == list[tuple[State, Action, float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(env: GridEnv, policy: Policy, max_t=10) -> Episode:\n",
    "    \"\"\"Generates an Monte Carlo episode in the Grid World environment GridEnv.\"\"\"\n",
    "    t = 0\n",
    "    episode = []\n",
    "    state = env.reset()\n",
    "    while t < max_t:\n",
    "        action: Action = policy(state) # select an action via the policy\n",
    "        next, reward, done = env.step(action) # get next_state, reward, done from the environment.\n",
    "        episode.append((state, action, reward))\n",
    "        state = env.state\n",
    "        t += 1 \n",
    "        if done:\n",
    "            break \n",
    "    \n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my episode = [(State(x=0, y=0), <Action.LEFT: 4>, 0.0), (State(x=0, y=0), <Action.LEFT: 4>, 0.0), (State(x=0, y=0), <Action.LEFT: 4>, 0.0)]\n",
      "my episode = [(State(x=0, y=0), <Action.RIGHT: 2>, 0.0), (State(x=1, y=0), <Action.RIGHT: 2>, 0.0), (State(x=2, y=0), <Action.RIGHT: 2>, 0.0), (State(x=3, y=0), <Action.UP: 1>, -9.0)]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_env = GridEnv(MDP)\n",
    "test_policy = lambda _: Action.LEFT\n",
    "test_episode = generate_episode(test_env, test_policy, max_t=3)\n",
    "assert len(test_episode) == 3\n",
    "assert test_episode[0] == (State(0, 0), Action.LEFT, 0.0)\n",
    "assert test_episode[1] == (State(0, 0), Action.LEFT, 0.0)\n",
    "assert test_episode[2] == (State(0, 0), Action.LEFT, 0.0)\n",
    "\n",
    "test_policy = lambda s: Action.UP if s == State(3, 0) else Action.RIGHT\n",
    "test_episode = generate_episode(test_env, test_policy)\n",
    "assert len(test_episode) == 4\n",
    "assert test_episode[0] == (State(0, 0), Action.RIGHT, 0.0)\n",
    "assert test_episode[1] == (State(1, 0), Action.RIGHT, 0.0)\n",
    "assert test_episode[2] == (State(2, 0), Action.RIGHT, 0.0)\n",
    "assert test_episode[3] == (State(3, 0), Action.UP, -9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But _how_ do we choose the actions in our Monte Carlo algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy and ε-greedy Policy\n",
    "\n",
    "A _greedy_ policy always chooses the action that maximizes the Q function in the current state.\n",
    "\n",
    "An _ε-greedy_ policy chooses any other action (other than the best action) with probability\n",
    "$\\frac{\\epsilon}{n_A}$, where $n_A$ is the number of available actions. Hence, if ε is `1`,\n",
    "the policy becomes the random policy; if ε is `0`, the policy is greedy instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gridworld import QTable\n",
    "\n",
    "def greedy_policy(qtable: QTable) -> Policy:\n",
    "    \"\"\"Returns the greedy policy for the specified QTable.\"\"\"\n",
    "    return lambda s: qtable.best_action(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the implementation\n",
    "state_0 = State(0, 0)\n",
    "state_1 = State(1, 0)\n",
    "test_qtable = QTable([state_0, state_1], list(Action))\n",
    "\n",
    "test_qtable[state_0, Action.DOWN]  = 0.5\n",
    "test_qtable[state_0, Action.LEFT]  = 1.5\n",
    "test_qtable[state_0, Action.RIGHT] = 0.8\n",
    "test_qtable[state_1, Action.UP]    = 0.1\n",
    "\n",
    "test_greedy_policy = greedy_policy(test_qtable)\n",
    "\n",
    "assert test_greedy_policy(state_0) == Action.LEFT\n",
    "assert test_greedy_policy(state_1) == Action.UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gridworld import QTable\n",
    "\n",
    "def epsilon_greedy_policy(qtable: QTable, epsilon: float) -> Policy:\n",
    "    \"\"\"Returns the epsilon-greedy policy for the specified QTable.\"\"\"\n",
    "    def choose_action(state: State):\n",
    "\n",
    "        best_action = qtable.best_action(state)\n",
    "        actions = qtable.actions \n",
    "        prob_dist = list([(epsilon / len(actions)) for a in actions])\n",
    "        best_action_idx = actions.index(best_action)\n",
    "        prob_dist[best_action_idx] = (1-epsilon) + (epsilon / len(actions))\n",
    "        #print(f\"epsilon = {epsilon}, prob dist={prob_dist}\")\n",
    "        return np.random.choice(actions,p=prob_dist)\n",
    "    return choose_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the implementation\n",
    "# Approximate tests... hopefully good enough to find big bugs :)\n",
    "state_0 = State(0, 0)\n",
    "state_1 = State(1, 0)\n",
    "test_qtable = QTable([state_0, state_1], list(Action))\n",
    "\n",
    "test_qtable[state_0, Action.DOWN]  = 0.5\n",
    "test_qtable[state_0, Action.LEFT]  = 1.5\n",
    "test_qtable[state_0, Action.RIGHT] = 0.8\n",
    "test_qtable[state_1, Action.UP]    = 0.1\n",
    "\n",
    "def probe_actions(policy, state) -> list[Action]:\n",
    "    return dict.fromkeys([policy(state) for _ in range(5_000)])\n",
    "\n",
    "test_egreedy_policy = epsilon_greedy_policy(test_qtable, epsilon=1.0)\n",
    "assert len(probe_actions(test_egreedy_policy, state_0)) == 4\n",
    "assert len(probe_actions(test_egreedy_policy, state_1)) == 4\n",
    "\n",
    "test_egreedy_policy = epsilon_greedy_policy(test_qtable, epsilon=0.0)\n",
    "assert len(probe_actions(test_egreedy_policy, state_0)) == 1\n",
    "assert len(probe_actions(test_egreedy_policy, state_1)) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This implementation technique (i.e., returning a function) is not optimal and definitely\n",
    "not efficient. But it serves well for learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decay Epsilon with Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_gen(eps_start=1.0, eps_decay=0.99999, eps_min=0.05):\n",
    "    \"\"\"Convenient generator function to generate and decy epsilon.\"\"\"\n",
    "    eps = eps_start\n",
    "    while True:\n",
    "        yield eps\n",
    "        eps = max(eps * eps_decay, eps_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the implementation!\n",
    "eps = epsilon_gen(1.0, 0.5, 0.1)\n",
    "\n",
    "assert next(eps) == 1.0\n",
    "assert next(eps) == 0.5\n",
    "assert next(eps) == 0.25\n",
    "assert next(eps) == 0.125\n",
    "assert next(eps) == 0.1\n",
    "assert next(eps) == 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(env: GridEnv, num_episodes, alpha=0.02, eps_start=1.0, start_q: QTable = None):\n",
    "    \"\"\"A Monte Carlo algorithm for reinforcement learning.\"\"\"\n",
    "    # TODO: Initialize the QTable (use start_q if provided, you'll see why later)\n",
    "    Q = start_q if start_q is not None else QTable()\n",
    "\n",
    "    # TODO: Prepare to generate epsilon creating the generator.\n",
    "    epsilon = epsilon_gen(eps_start,alpha,0)\n",
    "    \n",
    "\n",
    "    # Iterate until we reached the maximum number of episodes for learning.\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        # TODO: Generate an episode by following epsilon-greedy policy.\n",
    "        policy = None\n",
    "        episode = None\n",
    "\n",
    "        # TODO: Unpack the episode in a tuple of (list[states], list[actions], list[rewards]).\n",
    "        #       Hint: use the zip function!\n",
    "        states, actions, rewards = None\n",
    "\n",
    "        # TODO: Conveniently compute the discounts first. We can do this b/c we can compute all the\n",
    "        #       expected returns at each timestep (having all the rewards).\n",
    "        #       The discounts are: [1, gamma, gamma^2, gamma^3, ...] for the length of the episode.\n",
    "        discounts = None\n",
    "\n",
    "        # For each step / transition in the environment, let's update the QTable according to the\n",
    "        # update rule of Monte Carlo methods defined above.\n",
    "        for t, state in enumerate(states):\n",
    "            # TODO: Get the action at timestep `t` and the current state-action value.\n",
    "            action = None\n",
    "            old_Q = None\n",
    "            # TODO: Compute the total return. Recall that:\n",
    "            #       G_0 = R_1 + gamma * R_2 + gamma^2 * R_3 + ... (R1 is found at index 0)\n",
    "            #       Hint: sum rewards _from_ `t` onward, while select discounts _until_ `t`. That is\n",
    "            #       because discounts always start from the beginning even if rewards \"shift\".\n",
    "            G_t = None\n",
    "            Q[state, action] = None\n",
    "\n",
    "        # Monitor progress\n",
    "        if i_episode % 1000 == 0:\n",
    "            print(f\"\\rEpisode {i_episode}/{num_episodes}.\", end=\"\")\n",
    "\n",
    "    # TODO: Determine the optimal policy  (i.e., the greedy policy on the computed QTable).\n",
    "    policy = None\n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = GridEnv(MDP)\n",
    "\n",
    "# With minimal exploration\n",
    "biased_q = QTable(ENV.mdp.all_states, ENV.mdp.all_actions)\n",
    "biased_q[State(0, 0), Action.RIGHT] = 0.1\n",
    "biased_q[State(1, 0), Action.RIGHT] = 0.1\n",
    "biased_q[State(2, 0), Action.UP]    = 0.1\n",
    "\n",
    "minimal_exploration_policy, Q = monte_carlo(ENV, 100_000, eps_start=0.05, start_q=biased_q)\n",
    "run_simulation(ENV.mdp, minimal_exploration_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With exploration\n",
    "optimal_policy, Q = monte_carlo(ENV, 100_000, start_q=biased_q)\n",
    "run_simulation(ENV.mdp, optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration vs. Exploitation Tradeoff\n",
    "\n",
    "We can prove that MC converges to the optimal policy when these conditions are met:\n",
    "\n",
    " * Every state-action pair is visited infinitely many times; and\n",
    " * The policy converges to a policy that is greedy with respect to the action-value function Q.\n",
    "\n",
    "These are called the GLIE (Greedy in the Limit with Infinite Exploration) conditions, and guarantee\n",
    "that the agent continues exploring for all time steps, and grdually exploits more exploring less.\n",
    "\n",
    "Try to tune `alpha` and `epsilon` and see the effects on the performance of the algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Difference Methods\n",
    "\n",
    "Monte Carlo methods need to wait until the end of the episode to update our value estimates. Could\n",
    "we find a way to integrate knowledge earlier than that? Temporal Difference (TD) methods come to the\n",
    "rescue: they update the current value estimate based on the immediate reward and _another_ estimate.\n",
    "Hence, the update rule looks something like this:\n",
    "\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\{[R_t + \\gamma V^{estimate}(S_{t+1})] - Q(S_t, A_t)\\}\n",
    "$$\n",
    "\n",
    "\n",
    "$R_t + \\gamma V^{estimate}(S_{t+1})$ is called the _TD target_. If our estimate was perfect, you can\n",
    "notice it is effectively equivalent to $G_t$. Then, the _TD error_ $\\delta^{TD}$ is:\n",
    "$TD^{target} - Q(S_t, A_t)$. The equation above can be simplified as:\n",
    "\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\delta^{TD}\n",
    "$$\n",
    "\n",
    "Choosing the estimate of the value function is what differentiates various TD algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Learning\n",
    "\n",
    "Q Learning is probably the most popular TD algorithm. In Q Learning, we choose the estimate of the\n",
    "next value as: $\\max Q(S_{t+1}, A_{t+1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env: GridEnv, num_episodes, alpha=0.02, max_t=10):\n",
    "    \"\"\"Runs Q Learning.\"\"\"\n",
    "    # TODO: Initialize the QTable, and the epsilon generator.\n",
    "    Q = None\n",
    "    epsilon = None\n",
    "    # Run for the maximum number of episodes passed as input.\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        t = 0\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            # TODO: Select an action with an epsilon greedy policy using Q.\n",
    "            policy = None\n",
    "            action = None\n",
    "            # TODO: Interact with the environment\n",
    "            next_state, reward, done = None\n",
    "            # TODO: Store the current Q(s,a) value.\n",
    "            cur_value = None\n",
    "            # TODO: Determine the next_action using maxQ.\n",
    "            next_action = None\n",
    "            # TODO: Compute the TD target.\n",
    "            td_target = None\n",
    "            # TODO: Compute the TD error.\n",
    "            td_error  = None\n",
    "            # TODO: Update Q with the temporal-difference update rule.\n",
    "            Q[state, action] = None\n",
    "\n",
    "            # Update the state for the next cycle, and check for episode completion.\n",
    "            state = next_state\n",
    "            t = t + 1\n",
    "            if done or t >= max_t:\n",
    "                break\n",
    "        # Monitor and debugging messages.\n",
    "        if i_episode % 1000 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "    # TODO: Return the optimal policy as the greedy policy on Q.\n",
    "    policy = None\n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_policy, Q = q_learning(ENV, 100_000)\n",
    "run_simulation(ENV.mdp, opt_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to converge, Q Learning needs to explore enough and eventually make the learning rate small\n",
    "enough, but not decrease it too quickly either... :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off-Policy vs. On-Policy\n",
    "\n",
    "Q Learning is an _off-policy_ algorithm: the policy function is learnt by estimating the value of\n",
    "the next state using a separate policy (i.e., the greedy policy, maximizing the current Q value)\n",
    "compared to the policy that is actually followed (i.e., $\\epsilon$-greedy).\n",
    "\n",
    "That is different from _on-policy_ learning, where we learn and refine the policy function using\n",
    "actions taken via our current followed and learnt policy $\\pi(a|s)$. See [this post](https://stats.stackexchange.com/questions/184657/what-is-the-difference-between-off-policy-and-on-policy-learning) for a more in-depth explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Methods Limitations\n",
    "\n",
    "Cannot scale to large state / action spaces. Discretization is one approach, but there are better ones :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "### N-step Bootstrapping\n",
    "\n",
    "Sometimes neither Monte Carlo nor TD are the best fit. We should think them like the end of a\n",
    "spectrum: TD uses the immediate next reward, MC uses all (possibly infinite) rewards. Nothing\n",
    "prevents us to use any intermetiate number of rewards and then an estimate: this process is called\n",
    "_n-step bootstrapping_. More details in the Sutton and Barto book :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlzh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
